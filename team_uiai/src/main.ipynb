{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lixado/IKT452_computer_vision/MapAI-Competition-Private/env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from competition_toolkit.dataloader import download_dataset\n",
    "from torch.utils.data import Dataset\n",
    "from yaml import load, dump, Loader, Dumper\n",
    "import argparse\n",
    "from train import create_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset mapai_training_data (/home/lixado/.cache/huggingface/datasets/sjyhne___mapai_training_data/building_segmentation/1.0.0/b0b52f8c47ddbeae1962ab524cabb5fbed58d91cc70f9ac4c5981c071ad5f248)\n",
      "Found cached dataset mapai_training_data (/home/lixado/.cache/huggingface/datasets/sjyhne___mapai_training_data/building_segmentation/1.0.0/b0b52f8c47ddbeae1962ab524cabb5fbed58d91cc70f9ac4c5981c071ad5f248)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['image', 'lidar', 'mask'],\n",
      "    num_rows: 7000\n",
      "})\n",
      "Sample: {'image': '../../data/train/images/6179_495_44.tif', 'lidar': '../../data/train/lidar/6179_495_44.tif', 'mask': '../../data/train/masks/6179_495_44.tif'}\n",
      "Dataset({\n",
      "    features: ['image', 'lidar', 'mask'],\n",
      "    num_rows: 1500\n",
      "})\n",
      "Sample: {'image': '../../data/validation/images/6305_471_68.tif', 'lidar': '../../data/validation/lidar/6305_471_68.tif', 'mask': '../../data/validation/masks/6305_471_68.tif'}\n"
     ]
    }
   ],
   "source": [
    "trainDataset = download_dataset(\"train\", 1, get_dataset=True)\n",
    "testDataset = download_dataset(\"validation\", 1, get_dataset=True)\n",
    "\n",
    "print(trainDataset)\n",
    "print(f'Sample: {trainDataset[0]}')\n",
    "print(testDataset)\n",
    "print(f'Sample: {testDataset[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset mapai_training_data (/home/lixado/.cache/huggingface/datasets/sjyhne___mapai_training_data/building_segmentation/1.0.0/b0b52f8c47ddbeae1962ab524cabb5fbed58d91cc70f9ac4c5981c071ad5f248)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using number of images in traindataset: 7000/7000\n",
      "torch.Size([8, 3, 500, 500])\n",
      "torch.Size([8, 500, 500])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "opts = {\n",
    "    \"epochs\":10,\n",
    "    \"lr\": 1e-3,\n",
    "    \"config\": \"config/data.yaml\",\n",
    "    \"device\": \"cpu\",\n",
    "    \"task\": 1,\n",
    "    \"data_ratio\": 1.0,\n",
    "    \"imagesize\": 500,\n",
    "    \"task1\": {\n",
    "        \"batchsize\": 8,\n",
    "        \"shuffle\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "trainloader = iter(create_dataloader(opts, \"train\"))\n",
    "\n",
    "batch = next(trainloader)\n",
    "image, label, filename = batch\n",
    "image = image.to(opts[\"device\"])\n",
    "label = label.to(opts[\"device\"])\n",
    "print(image.shape)\n",
    "print(label.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, 3, stride=2, padding=1), # torch.Size([128, 8, 32, 32])\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=1),\n",
    "            nn.Conv2d(8, 12, 2, stride=1, padding=1), \n",
    "            nn.BatchNorm2d(12),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=1),\n",
    "            nn.Conv2d(12, 16, 2, stride=1, padding=1), \n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=1),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1), # torch.Size([128, 32, 16, 16])\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=1),\n",
    "            nn.Conv2d(32, 64, 7),  # torch.Size([128, 64, 9, 9])\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "\n",
    "encoded = encoder(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64, 118, 118])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 500, 500])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 7), # torch.Size([128, 32, 15, 15])\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 12, 2, stride=2),\n",
    "            nn.BatchNorm2d(12),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(12, 8, 4, stride=1),\n",
    "            nn.BatchNorm2d(8),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 1, 2, stride=1), # torch.Size([128, 3, 64, 64])\n",
    "            nn.Tanh()\n",
    "        ) \n",
    "\n",
    "decoded = decoder(encoded)\n",
    "decoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 500, 500])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = torch.squeeze(decoded, dim=1)\n",
    "\n",
    "new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -0.0624576210975647, Max: 0.8567994832992554, Min: -0.7377985715866089\n",
      "Mean: 0.06282700598239899, Max: 0.8567994832992554, Min: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8, 249, 249])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = nn.Conv2d(3, 8, kernel_size=(3,3), stride=2)(image)\n",
    "print(f\"Mean: {torch.mean(x)}, Max: {torch.max(x)}, Min: {torch.min(x)}\")\n",
    "x = nn.ReLU(True)(x)\n",
    "print(f\"Mean: {torch.mean(x)}, Max: {torch.max(x)}, Min: {torch.min(x)}\")\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -0.020735396072268486, Max: 0.3811044991016388, Min: -0.3278544247150421\n",
      "Mean: 0.0362386479973793, Max: 0.3811044991016388, Min: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16, 247, 247])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = nn.Conv2d(8, 16, kernel_size=(3,3), stride=1)(x)\n",
    "print(f\"Mean: {torch.mean(x)}, Max: {torch.max(x)}, Min: {torch.min(x)}\")\n",
    "x = nn.ReLU(True)(x)\n",
    "print(f\"Mean: {torch.mean(x)}, Max: {torch.max(x)}, Min: {torch.min(x)}\")\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: -0.0015695798210799694, Max: 0.1335599720478058, Min: -0.11457626521587372\n",
      "Mean: 0.016312049701809883, Max: 0.1335599720478058, Min: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 32, 243, 243])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = nn.Conv2d(16, 32, kernel_size=(5,5), stride=1)(x)\n",
    "print(f\"Mean: {torch.mean(x)}, Max: {torch.max(x)}, Min: {torch.min(x)}\")\n",
    "x = nn.ReLU(True)(x)\n",
    "print(f\"Mean: {torch.mean(x)}, Max: {torch.max(x)}, Min: {torch.min(x)}\")\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.0006744005950167775, Max: 0.10606221109628677, Min: -0.07724209874868393\n",
      "Mean: 0.012780619785189629, Max: 0.10606221109628677, Min: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64, 239, 239])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = nn.Conv2d(32, 64, kernel_size=(5,5), stride=1)(x)\n",
    "print(f\"Mean: {torch.mean(x)}, Max: {torch.max(x)}, Min: {torch.min(x)}\")\n",
    "x = nn.ReLU(True)(x)\n",
    "print(f\"Mean: {torch.mean(x)}, Max: {torch.max(x)}, Min: {torch.min(x)}\")\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.0008399624493904412, Max: 0.04235048219561577, Min: -0.051030874252319336\n",
      "Mean: 0.008168298751115799, Max: 0.04235048219561577, Min: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64, 118, 118])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = nn.Conv2d(64, 64, kernel_size=(5,5), stride=2)(x)\n",
    "print(f\"Mean: {torch.mean(x)}, Max: {torch.max(x)}, Min: {torch.min(x)}\")\n",
    "x = nn.ReLU(True)(x)\n",
    "print(f\"Mean: {torch.mean(x)}, Max: {torch.max(x)}, Min: {torch.min(x)}\")\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.004215300548821688, Max: 0.037832312285900116, Min: -0.03804945945739746\n",
      "Mean: 0.009681029245257378, Max: 0.037832312285900116, Min: 0.0\n",
      "torch.Size([8, 64, 57, 57])\n",
      "torch.Size([8, 207936])\n"
     ]
    }
   ],
   "source": [
    "x = nn.Conv2d(64, 64, kernel_size=(5,5), stride=2)(x)\n",
    "print(f\"Mean: {torch.mean(x)}, Max: {torch.max(x)}, Min: {torch.min(x)}\")\n",
    "x = nn.ReLU(True)(x)\n",
    "print(f\"Mean: {torch.mean(x)}, Max: {torch.max(x)}, Min: {torch.min(x)}\")\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "x = nn.Flatten()(x)\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.00017022066458594054, Max: 0.036702558398246765, Min: -0.032442498952150345\n",
      "Mean: 0.003443444613367319, Max: 0.036702558398246765, Min: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3249])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = nn.Linear(64*57*57, 57*57)(x)\n",
    "print(f\"Mean: {torch.mean(x)}, Max: {torch.max(x)}, Min: {torch.min(x)}\")\n",
    "x = nn.ReLU(True)(x)\n",
    "print(f\"Mean: {torch.mean(x)}, Max: {torch.max(x)}, Min: {torch.min(x)}\")\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 2.619838051032275e-05, Max: 0.03162980452179909, Min: -0.030906712636351585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 207936])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = nn.Linear(57*57, 64*57*57)(x)\n",
    "print(f\"Mean: {torch.mean(x)}, Max: {torch.max(x)}, Min: {torch.min(x)}\")\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.00456753745675087, Max: 0.03162980452179909, Min: 0.0\n"
     ]
    }
   ],
   "source": [
    "x = nn.ReLU(True)(x)\n",
    "print(f\"Mean: {torch.mean(x)}, Max: {torch.max(x)}, Min: {torch.min(x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = nn.ConvTranspose2d(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8cb23e0453d29d6a9624bbad90ee62cc43a7d69daeeb30dedf8e2013a6afbd09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
